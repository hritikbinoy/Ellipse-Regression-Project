{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe27200",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook exports the trained Brevitas quantized regression CNN into a FINN-compatible QONNX model.\n",
    "\n",
    "This step is mandatory for FINN and bridges:\n",
    "\n",
    "1-Model.ipynb ‚Üí FINN toolflow\n",
    "\n",
    "The output of this notebook is:\n",
    "\n",
    "model_regression_qonnx.onnx\n",
    "\n",
    "This file will be consumed by 2-finn.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb688974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "\n",
    "import brevitas.nn as qnn\n",
    "import brevitas.quant as quant\n",
    "from brevitas.export import export_qonnx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c56bb5",
   "metadata": {},
   "source": [
    "## Import model definitions \n",
    "\n",
    "These definitions are taken directly from 1-Model.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a610cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import brevitas.nn as qnn\n",
    "import brevitas.quant as quant\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# FP32 reference model (used only to load weights)\n",
    "# =========================================================\n",
    "class EllipseRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Quantized QAT model (this is what FINN consumes)\n",
    "# =========================================================\n",
    "class QuantEllipseRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = qnn.QuantConv2d(1, 32, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint)\n",
    "        self.conv2 = qnn.QuantConv2d(32, 64, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint)\n",
    "        self.conv3 = qnn.QuantConv2d(64, 128, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint)\n",
    "        self.conv4 = qnn.QuantConv2d(128, 256, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.relu = qnn.QuantReLU(bit_width=8)\n",
    "        self.fc1 = qnn.QuantLinear(256, 128, weight_quant=quant.Int8WeightPerTensorFixedPoint)\n",
    "        self.fc2 = qnn.QuantLinear(128, 5, weight_quant=quant.Int8WeightPerTensorFixedPoint)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0cb0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Quantized QAT model - CORRECTED to match checkpoint\n",
    "# =========================================================\n",
    "class QuantEllipseRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Conv layers WITHOUT bias (BatchNorm handles the bias)\n",
    "        self.conv1 = qnn.QuantConv2d(1, 32, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = qnn.QuantConv2d(32, 64, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = qnn.QuantConv2d(64, 128, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = qnn.QuantConv2d(128, 256, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.act = qnn.QuantReLU(bit_width=8)\n",
    "        self.fc1 = qnn.QuantLinear(256, 512, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=False)\n",
    "        self.fc2 = qnn.QuantLinear(512, 256, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=False)\n",
    "        self.fc_out = nn.Linear(256, 5, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.act(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.act(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.act(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9cff2",
   "metadata": {},
   "source": [
    "## Load trained QAT weights\n",
    "\n",
    "These are the same weights you trained in 1-Model.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040cb5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantEllipseRegressionModel(\n",
       "  (conv1): QuantConv2d(\n",
       "    1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): PowerOfTwoRestrictValue(\n",
       "                (float_to_int_impl): CeilSte()\n",
       "                (power_of_two): PowerOfTwo()\n",
       "              )\n",
       "            )\n",
       "            (restrict_scaling_pre): LogTwo()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): PowerOfTwoIntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): QuantConv2d(\n",
       "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): PowerOfTwoRestrictValue(\n",
       "                (float_to_int_impl): CeilSte()\n",
       "                (power_of_two): PowerOfTwo()\n",
       "              )\n",
       "            )\n",
       "            (restrict_scaling_pre): LogTwo()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): PowerOfTwoIntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): QuantConv2d(\n",
       "    64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): PowerOfTwoRestrictValue(\n",
       "                (float_to_int_impl): CeilSte()\n",
       "                (power_of_two): PowerOfTwo()\n",
       "              )\n",
       "            )\n",
       "            (restrict_scaling_pre): LogTwo()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): PowerOfTwoIntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): QuantConv2d(\n",
       "    128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): PowerOfTwoRestrictValue(\n",
       "                (float_to_int_impl): CeilSte()\n",
       "                (power_of_two): PowerOfTwo()\n",
       "              )\n",
       "            )\n",
       "            (restrict_scaling_pre): LogTwo()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): PowerOfTwoIntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (act): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): QuantLinear(\n",
       "    in_features=256, out_features=512, bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): PowerOfTwoRestrictValue(\n",
       "                (float_to_int_impl): CeilSte()\n",
       "                (power_of_two): PowerOfTwo()\n",
       "              )\n",
       "            )\n",
       "            (restrict_scaling_pre): LogTwo()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): PowerOfTwoIntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (fc2): QuantLinear(\n",
       "    in_features=512, out_features=256, bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): PowerOfTwoRestrictValue(\n",
       "                (float_to_int_impl): CeilSte()\n",
       "                (power_of_two): PowerOfTwo()\n",
       "              )\n",
       "            )\n",
       "            (restrict_scaling_pre): LogTwo()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): PowerOfTwoIntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=256, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = QuantEllipseRegressionModel()\n",
    "model.load_state_dict(torch.load(\"ellipse_qat_best.pth\", map_location=\"cpu\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85262002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantEllipseRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = qnn.QuantConv2d(1, 32, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = qnn.QuantConv2d(32, 64, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = qnn.QuantConv2d(64, 128, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = qnn.QuantConv2d(128, 256, 3, padding=1, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=True)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.act = qnn.QuantReLU(bit_width=8)\n",
    "        self.fc1 = qnn.QuantLinear(256, 512, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=True)\n",
    "        self.fc2 = qnn.QuantLinear(512, 256, weight_quant=quant.Int8WeightPerTensorFixedPoint, bias=False)\n",
    "        self.fc_out = nn.Linear(256, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.act(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.act(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.act(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af4ed3",
   "metadata": {},
   "source": [
    "## Define dummy input (static shape required by FINN)\n",
    "\n",
    "FINN requires fixed spatial dimensions during ONNX export.\n",
    "\n",
    "Input specification:\n",
    "\n",
    "Grayscale image\n",
    "\n",
    "Shape: (N, 1, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3caf68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 1, 20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b69be7",
   "metadata": {},
   "source": [
    "## Export to FINN-compatible QONNX\n",
    "\n",
    "‚ö†Ô∏è Do NOT use torch.onnx.export\n",
    "\n",
    "Always use Brevitas QONNX exporter so that:\n",
    "\n",
    "Quantization metadata is preserved\n",
    "\n",
    "Bit-widths are explicitly encoded\n",
    "\n",
    "FINN can infer datatypes correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399ac176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Exported QONNX model to: ellipse_regression_qonnx.onnx\n"
     ]
    }
   ],
   "source": [
    "export_path = \"ellipse_regression_qonnx.onnx\"\n",
    "\n",
    "\n",
    "export_qonnx(\n",
    "model,\n",
    "dummy_input,\n",
    "export_path=export_path\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Exported QONNX model to:\", export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a8b92",
   "metadata": {},
   "source": [
    "## Verify ONNX model correctness\n",
    "\n",
    "This ensures the exported model is structurally valid before FINN processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fafbfbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model check passed ‚úî\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(export_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model check passed ‚úî\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29809a",
   "metadata": {},
   "source": [
    "## (Optional but recommended) Quick inference sanity check\n",
    "\n",
    "This confirms that the exported model produces outputs with the expected shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdced9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 5])\n",
      "Expected: torch.Size([1, 5])\n",
      "‚úÖ Inference sanity check passed!\n"
     ]
    }
   ],
   "source": [
    "# Cell : (Optional but recommended) Quick inference sanity check\n",
    "with torch.no_grad():\n",
    "    out = model(dummy_input)\n",
    "    print(\"Output shape:\", out.shape)\n",
    "    print(\"Expected: torch.Size([1, 5])\")\n",
    "    \n",
    "    # Verify output is valid\n",
    "    assert out.shape == (1, 5), f\"Expected shape (1, 5), got {out.shape}\"\n",
    "    print(\"‚úÖ Inference sanity check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c947e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ONNX model check passed\n",
      "‚úÖ Model name: torch_jit\n",
      "‚úÖ Opset version: 14\n",
      "‚úÖ Producer: pytorch\n",
      "\n",
      "üìä Total nodes: 34\n",
      "\n",
      "üîç Node type breakdown:\n",
      "  Quant: 11\n",
      "  Relu: 5\n",
      "  Conv: 4\n",
      "  BatchNormalization: 4\n",
      "  MaxPool: 4\n",
      "  MatMul: 3\n",
      "  Transpose: 2\n",
      "  Reshape: 1\n",
      "\n",
      "üì• Inputs: 18\n",
      "  - x.7: [1, 1, 20, 20]\n",
      "  - bn1.weight: [32]\n",
      "  - bn1.bias: [32]\n",
      "  - bn1.running_mean: [32]\n",
      "  - bn1.running_var: [32]\n",
      "  - bn2.weight: [64]\n",
      "  - bn2.bias: [64]\n",
      "  - bn2.running_mean: [64]\n",
      "  - bn2.running_var: [64]\n",
      "  - bn3.weight: [128]\n",
      "  - bn3.bias: [128]\n",
      "  - bn3.running_mean: [128]\n",
      "  - bn3.running_var: [128]\n",
      "  - bn4.weight: [256]\n",
      "  - bn4.bias: [256]\n",
      "  - bn4.running_mean: [256]\n",
      "  - bn4.running_var: [256]\n",
      "  - onnx::MatMul_86: [256, 5]\n",
      "\n",
      "üì§ Outputs: 1\n",
      "  - 82: [1, 5]\n"
     ]
    }
   ],
   "source": [
    "# Cell : Verify QONNX Export\n",
    "import onnx\n",
    "from collections import Counter\n",
    "\n",
    "onnx_model = onnx.load(export_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "print(\"‚úÖ ONNX model check passed\")\n",
    "print(f\"‚úÖ Model name: {onnx_model.graph.name}\")\n",
    "print(f\"‚úÖ Opset version: {onnx_model.opset_import[0].version}\")\n",
    "print(f\"‚úÖ Producer: {onnx_model.producer_name}\")\n",
    "\n",
    "# Count node types\n",
    "node_types = [node.op_type for node in onnx_model.graph.node]\n",
    "print(f\"\\nüìä Total nodes: {len(node_types)}\")\n",
    "print(\"\\nüîç Node type breakdown:\")\n",
    "for op_type, count in Counter(node_types).most_common():\n",
    "    print(f\"  {op_type}: {count}\")\n",
    "\n",
    "# Check inputs and outputs\n",
    "print(f\"\\nüì• Inputs: {len(onnx_model.graph.input)}\")\n",
    "for inp in onnx_model.graph.input:\n",
    "    shape = [dim.dim_value for dim in inp.type.tensor_type.shape.dim]\n",
    "    print(f\"  - {inp.name}: {shape}\")\n",
    "\n",
    "print(f\"\\nüì§ Outputs: {len(onnx_model.graph.output)}\")\n",
    "for out in onnx_model.graph.output:\n",
    "    shape = [dim.dim_value for dim in out.type.tensor_type.shape.dim]\n",
    "    print(f\"  - {out.name}: {shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd1059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Skipping ONNX Runtime test\n",
      "   Reason: QONNX models contain Brevitas custom ops (e.g., 'Quant')\n",
      "   that are not supported by standard ONNX Runtime.\n",
      "\n",
      "‚úÖ This model is designed for FINN compilation.\n",
      "   FINN will handle the custom quantization operators.\n",
      "\n",
      "üìä Model Info:\n",
      "  - Nodes: 34\n",
      "  - Inputs: 18\n",
      "  - Outputs: 1\n",
      "  - Opset: 14\n",
      "\n",
      "üéØ Brevitas QONNX operators found: Quant\n",
      "   ‚úÖ Model ready for FINN!\n"
     ]
    }
   ],
   "source": [
    "# Cell : Verify QONNX Model (Skip ONNX Runtime - use for FINN only)\n",
    "print(\"‚ÑπÔ∏è Skipping ONNX Runtime test\")\n",
    "print(\"   Reason: QONNX models contain Brevitas custom ops (e.g., 'Quant')\")\n",
    "print(\"   that are not supported by standard ONNX Runtime.\")\n",
    "print(\"\")\n",
    "print(\"‚úÖ This model is designed for FINN compilation.\")\n",
    "print(\"   FINN will handle the custom quantization operators.\")\n",
    "\n",
    "# Instead, verify the model structure\n",
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(export_path)\n",
    "print(f\"\\nüìä Model Info:\")\n",
    "print(f\"  - Nodes: {len(onnx_model.graph.node)}\")\n",
    "print(f\"  - Inputs: {len(onnx_model.graph.input)}\")\n",
    "print(f\"  - Outputs: {len(onnx_model.graph.output)}\")\n",
    "print(f\"  - Opset: {onnx_model.opset_import[0].version}\")\n",
    "\n",
    "# Check for Brevitas custom ops\n",
    "custom_ops = set()\n",
    "for node in onnx_model.graph.node:\n",
    "    if node.domain == \"onnx.brevitas\":\n",
    "        custom_ops.add(node.op_type)\n",
    "\n",
    "if custom_ops:\n",
    "    print(f\"\\nüéØ Brevitas QONNX operators found: {', '.join(custom_ops)}\")\n",
    "    print(\"   ‚úÖ Model ready for FINN!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No Brevitas QONNX operators found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c12eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'ellipse_regression_qonnx.onnx' at http://localhost:8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Launching Netron for: ellipse_regression_qonnx.onnx\n"
     ]
    }
   ],
   "source": [
    "# Cell: Launch Netron Visualizer\n",
    "\n",
    "import netron\n",
    "import os\n",
    "\n",
    "qonnx_path = \"ellipse_regression_qonnx.onnx\"\n",
    "if os.path.exists(qonnx_path):\n",
    "    print(f\" Launching Netron for: {qonnx_path}\")\n",
    "    netron.start(qonnx_path)\n",
    "else:\n",
    "    print(f\" File not found: {qonnx_path}\")\n",
    "    print(\"   Run the QONNX export cell first!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ellipse-qat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
